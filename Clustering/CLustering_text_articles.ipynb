{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "data = fetch_20newsgroups()\n",
    "print(data.target_names)\n",
    "x, y = fetch_20newsgroups(return_X_y=True)\n",
    "\n",
    "#fixing dimensions (not working)\n",
    "# x = np.array(x)\n",
    "# y= np.array(y)\n",
    "# x = x[:,np.newaxis]\n",
    "# y = y[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19]),\n",
       " array([480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591,\n",
       "        594, 593, 599, 546, 564, 465, 377], dtype=int64))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_number = len(np.unique(y))\n",
    "cluster_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shamelessly stealing Adrien's nice function for clustering benchmark:, \n",
    "\n",
    "def bench_clust(estimator, data, ground_truth = None,):\n",
    "    estimator.fit(data)\n",
    "    scores = [\n",
    "        \"adjusted_rand_score\",\n",
    "        \"adjusted_mutual_info_score\",\n",
    "        \"silhouette_score\",\n",
    "        \"homogeneity_score\",\n",
    "        \"completeness_score\",\n",
    "        \"v_measure_score\",\n",
    "    ]\n",
    "    results = []\n",
    "    for s in scores:\n",
    "        if s not in [\"silhouette_score\"]:\n",
    "            #where ground truth is provided\n",
    "            score = getattr(metrics, s)(ground_truth, estimator.labels_)\n",
    "        elif ground_truth is not None:\n",
    "            score = getattr(metrics, s)(data, estimator.labels_)\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "        results.append(score)\n",
    "    return pd.DataFrame([results], columns=scores, index=['Results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thaz\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Results</th>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.036738</td>\n",
       "      <td>0.114842</td>\n",
       "      <td>0.030586</td>\n",
       "      <td>0.074524</td>\n",
       "      <td>0.043372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         adjusted_rand_score  adjusted_mutual_info_score  silhouette_score  \\\n",
       "Results             0.009789                    0.036738          0.114842   \n",
       "\n",
       "         homogeneity_score  completeness_score  v_measure_score  \n",
       "Results           0.030586            0.074524         0.043372  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building train test split : \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=42)\n",
    "\n",
    "\n",
    "# failed to build a pipeline, it seems to cause a data dimension error that does not occur while working \"the handy way\", \n",
    "# # using CountVectorizer to extract tokens matrix, and kmeans as a model, in a sequence.\n",
    "vect = CountVectorizer()\n",
    "x_train_vec = vect.fit_transform(x_train)\n",
    "\n",
    "model = KMeans(n_clusters= cluster_number)\n",
    "\n",
    "#let's give it a try : \n",
    "bench_clust(model, x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thaz\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>adjusted_mutual_info_score</th>\n",
       "      <th>silhouette_score</th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Results</th>\n",
       "      <td>0.079343</td>\n",
       "      <td>0.247133</td>\n",
       "      <td>-0.006622</td>\n",
       "      <td>0.230287</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.253277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         adjusted_rand_score  adjusted_mutual_info_score  silhouette_score  \\\n",
       "Results             0.079343                    0.247133         -0.006622   \n",
       "\n",
       "         homogeneity_score  completeness_score  v_measure_score  \n",
       "Results           0.230287            0.281367         0.253277  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with tfidf\n",
    "\n",
    "better_vec = TfidfVectorizer()\n",
    "x_train_vec2 = better_vec.fit_transform(x_train)\n",
    "\n",
    "#let's give it a try : \n",
    "bench_clust(model, x_train_vec2, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
